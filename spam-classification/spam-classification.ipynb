{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classification\n",
    "An email spam classifier using NLTK (natural language processing toolkit) in Python. Using the bag of words (BOW) approach to building the model, after performing tokenizing, lemmatization / stemming, and removing stop words. \n",
    "\n",
    "Dataset: https://www.kaggle.com/chandramoulinaidu/spam-classification-for-basic-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...</td>\n",
       "      <td>00249.5f45607c1bffe89f60ba1ec9f878039a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ATTENTION: This is a MUST for ALL Computer Use...</td>\n",
       "      <td>00373.ebe8670ac56b04125c25100a36ab0510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a multi-part message in MIME format.\\n...</td>\n",
       "      <td>00214.1367039e50dc6b7adb0f2aa8aba83216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...</td>\n",
       "      <td>00210.050ffd105bd4e006771ee63cabc59978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the bottom line.  If you can GIVE AWAY...</td>\n",
       "      <td>00033.9babb58d9298daa2963d4f514193d7d6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CATEGORY                                            MESSAGE  \\\n",
       "0         1  Dear Homeowner,\\n\\n \\n\\nInterest Rates are at ...   \n",
       "1         1  ATTENTION: This is a MUST for ALL Computer Use...   \n",
       "2         1  This is a multi-part message in MIME format.\\n...   \n",
       "3         1  IMPORTANT INFORMATION:\\n\\n\\n\\nThe new domain n...   \n",
       "4         1  This is the bottom line.  If you can GIVE AWAY...   \n",
       "\n",
       "                                FILE_NAME  \n",
       "0  00249.5f45607c1bffe89f60ba1ec9f878039a  \n",
       "1  00373.ebe8670ac56b04125c25100a36ab0510  \n",
       "2  00214.1367039e50dc6b7adb0f2aa8aba83216  \n",
       "3  00210.050ffd105bd4e006771ee63cabc59978  \n",
       "4  00033.9babb58d9298daa2963d4f514193d7d6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/Spam Email raw text for NLP.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>MESSAGE</th>\n",
       "      <th>FILE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm one of the 30,000 but it's not working ver...</td>\n",
       "      <td>00609.dd49926ce94a1ea328cce9b62825bc97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0</td>\n",
       "      <td>Damien Morton quoted:\\n\\n&gt;W3C approves HTML 4 ...</td>\n",
       "      <td>00957.e0b56b117f3ec5f85e432a9d2a47801f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0</td>\n",
       "      <td>On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...</td>\n",
       "      <td>01127.841233b48eceb74a825417d8d918abf8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>Once upon a time, Manfred wrote :\\n\\n\\n\\n&gt; I w...</td>\n",
       "      <td>01178.5c977dff972cd6eef64d4173b90307f0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>If you run Pick, and then use the \"New FTOC\" b...</td>\n",
       "      <td>00747.352d424267d36975a7b40b85ffd0885e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CATEGORY                                            MESSAGE  \\\n",
       "5791         0  I'm one of the 30,000 but it's not working ver...   \n",
       "5792         0  Damien Morton quoted:\\n\\n>W3C approves HTML 4 ...   \n",
       "5793         0  On Mon, 2002-07-22 at 06:50, che wrote:\\n\\n\\n\\...   \n",
       "5794         0  Once upon a time, Manfred wrote :\\n\\n\\n\\n> I w...   \n",
       "5795         0  If you run Pick, and then use the \"New FTOC\" b...   \n",
       "\n",
       "                                   FILE_NAME  \n",
       "5791  00609.dd49926ce94a1ea328cce9b62825bc97  \n",
       "5792  00957.e0b56b117f3ec5f85e432a9d2a47801f  \n",
       "5793  01127.841233b48eceb74a825417d8d918abf8  \n",
       "5794  01178.5c977dff972cd6eef64d4173b90307f0  \n",
       "5795  00747.352d424267d36975a7b40b85ffd0885e  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "0    3900\n",
       "1    1896\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"CATEGORY\"].value_counts() # 1 = spam, 0 = not spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/eriklarsson/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eriklarsson/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey',\n",
       " 'GGggGG',\n",
       " 'feet',\n",
       " 'it',\n",
       " 'going',\n",
       " 'HTML',\n",
       " 'bads',\n",
       " 'bads',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "test_message = \"Hey,, GGggGG feet it going <HTML><bads> bads 'randoms' badly\"\n",
    "\n",
    "test_message_tokenized = tokenizer.tokenize(test_message)\n",
    "test_message_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'gggggg',\n",
       " 'feet',\n",
       " 'it',\n",
       " 'going',\n",
       " 'html',\n",
       " 'bads',\n",
       " 'bads',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message_lowercased = [t.lower() for t in test_message_tokenized]\n",
    "test_message_lowercased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey',\n",
       " 'gggggg',\n",
       " 'foot',\n",
       " 'it',\n",
       " 'going',\n",
       " 'html',\n",
       " 'bad',\n",
       " 'bad',\n",
       " 'randoms',\n",
       " 'badly']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "test_message_lemmatized = [lemmatizer.lemmatize(t) for t in test_message_lowercased]\n",
    "test_message_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_message_useful_tokens = [t for t in test_message_lemmatized if t not in stopwords]\n",
    "test_message_useful_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', 'gggggg', 'foot', 'going', 'html', 'bad', 'bad', 'randoms', 'badly']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def message_to_token_list(s):\n",
    "  tokens = tokenizer.tokenize(s)\n",
    "  lowercased_tokens = [t.lower() for t in tokens]\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(t) for t in lowercased_tokens]\n",
    "  useful_tokens = [t for t in lemmatized_tokens if t not in stopwords]\n",
    "\n",
    "  return useful_tokens\n",
    "\n",
    "message_to_token_list(test_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      CATEGORY                                            MESSAGE  \\\n",
       " 0            1  <HTML>\\n\\n<BODY>\\n\\n<META HTTP-EQUIV=3D\"Conten...   \n",
       " 1            1  <html>\\n\\n\\n\\n\\n\\n</head>\\n\\n\\n\\n<body>\\n\\n\\n\\...   \n",
       " 2            1  <HTML><HEAD><TITLE>New Web Technology</TITLE>\\...   \n",
       " 3            1  \\n\\n<HTML>\\n\\n<HEAD>\\n\\n<TITLE>bizmagoffer</TI...   \n",
       " 4            0  URL: http://boingboing.net/#85485824\\n\\nDate: ...   \n",
       " ...        ...                                                ...   \n",
       " 4631         0  Doom 3 will be based on a peer to peer archite...   \n",
       " 4632         1  \\n\\n\\n\\n<HTML>\\n\\n<HEAD>\\n\\n<TITLE>Cards In Ad...   \n",
       " 4633         1  <BODY BGCOLOR=\"#FFFFFF\">\\n\\n\\n\\n<DIV ALIGN=\"ce...   \n",
       " 4634         0  Yes - great minds think alike. But even withpu...   \n",
       " 4635         0  On Tue, Aug 06, 2002 at 04:21:22 +0100, David ...   \n",
       " \n",
       "                                    FILE_NAME  \n",
       " 0     00275.87c74dc27e397ccd3b2b581bbefef515  \n",
       " 1     00531.f3fffa4504c7009a03dd0d44a4562a84  \n",
       " 2     01078.58e6f465de71680b96d9d750b7200a59  \n",
       " 3     00627.4e9619c454da17a27d4a66c87583dd49  \n",
       " 4     01894.a6896770e24b5211fa506b0039343769  \n",
       " ...                                      ...  \n",
       " 4631  00328.3f61d8085d0a6376ce225b4d9e5630e8  \n",
       " 4632  00905.8dcb590481d3e3c04d03506100c59497  \n",
       " 4633  01002.406c1c709e49cb740f0ce36ebf2d5c78  \n",
       " 4634  00012.48a387bc38d1316a6f6b49e8c2e43a03  \n",
       " 4635  00048.74cb47cb518e1ad1628b49ebbeb9d2b6  \n",
       " \n",
       " [4636 rows x 3 columns],\n",
       "       CATEGORY                                            MESSAGE  \\\n",
       " 0            1  <html>\\n\\n<center>\\n\\n<font face=verdana color...   \n",
       " 1            1  <HTML><HEAD><TITLE>A Money Making Home Busines...   \n",
       " 2            1  Greetings -\\n\\n\\n\\nI understand you are intere...   \n",
       " 3            0  On Fri, 2002-08-09 at 19:13, Paul Linehan wrot...   \n",
       " 4            1  <style type=\"text/css\">\\n\\n<!--\\n\\na {  text-d...   \n",
       " ...        ...                                                ...   \n",
       " 1155         0  > Matthias Saou (matthias@egwn.net) wrote*:\\n\\...   \n",
       " 1156         0  MF> Here is a sample conversation on (MSN Mess...   \n",
       " 1157         0  Adam Goryachev wrote:\\n\\n> Just my $1 worth......   \n",
       " 1158         1  This is the bottom line.  If you can GIVE AWAY...   \n",
       " 1159         0  Thanks Matthias.  Actually I got all four spea...   \n",
       " \n",
       "                                    FILE_NAME  \n",
       " 0     00167.c37f166df54b89ce15059415cfbe12c3  \n",
       " 1     00377.8568faed5f5f8cd3fb0956786da98a1a  \n",
       " 2     00492.3052cad36d423e60195ce706c7bc0e6f  \n",
       " 3     00333.754374109f71535b61b3c5b6db54365a  \n",
       " 4     00751.3158a29a29997cc16a69497399d90ca2  \n",
       " ...                                      ...  \n",
       " 1155  01215.94a01e7d8bb1206fbb2f1cc7fb3dcdbd  \n",
       " 1156  00848.a99e7c1ff97407816f4c0b323421b5c9  \n",
       " 1157  00601.2f32c4ddbfc8c2c0c147ece6f7346de1  \n",
       " 1158  00033.9babb58d9298daa2963d4f514193d7d6  \n",
       " 1159  01287.c8de1608b71977e5dd6b71da6a2019d7  \n",
       " \n",
       " [1160 rows x 3 columns])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=1)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "split_index = int(len(df) * 0.8)\n",
    "train_df, test_df = df[:split_index], df[split_index:]\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76915"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter = {}\n",
    "\n",
    "for message in train_df['MESSAGE']:\n",
    "    message_as_token_lst = message_to_token_list(message)\n",
    "    for token in message_as_token_lst:\n",
    "        if token in token_counter:\n",
    "            token_counter[token] += 1\n",
    "        else:\n",
    "            token_counter[token] = 1\n",
    "\n",
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def keep_token(proccessed_token, threshold):\n",
    "  if proccessed_token not in token_counter:\n",
    "    return False\n",
    "  else:\n",
    "    return token_counter[proccessed_token] > threshold\n",
    "\n",
    "print(keep_token('random', 10))\n",
    "print(keep_token('random', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d', 'b', 'br', 'com', 'font', 'http', 'nbsp', 'p', 'size', 'td', 'tr'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = set()\n",
    "\n",
    "for token in token_counter:\n",
    "    if keep_token(token, 10000):\n",
    "        features.add(token)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tr', 'com', 'http', 'nbsp', 'size', 'font', 'br', '3d', 'td', 'b', 'p']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tr': 0,\n",
       " 'com': 1,\n",
       " 'http': 2,\n",
       " 'nbsp': 3,\n",
       " 'size': 4,\n",
       " 'font': 5,\n",
       " 'br': 6,\n",
       " '3d': 7,\n",
       " 'td': 8,\n",
       " 'b': 9,\n",
       " 'p': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_index_mapping = {t:i for t, i in zip(features, range(len(features)))}\n",
    "token_to_index_mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d', 'b', 'br', 'com', 'bad', 'font', 'font', 'com', 'randoms']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_to_token_list('3d b <br> .com bad font font com randoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Bag of Words\" (counts vector)\n",
    "\n",
    "# ->  http  tr  size  3d  font  br  com  td   p   b\n",
    "# ->    0    1    2    3   4    5    6    7   8   9\n",
    "# ->   [0,   0,   0,   1,  2,   1,   2,   0,  0,  1]\n",
    "\n",
    "[0.,  0.,  0.,   1., 2.,  1., 2.,  0., 0., 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 0., 0., 0., 2., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def message_to_count_vector(message):\n",
    "  count_vector = np.zeros(len(features))\n",
    "\n",
    "  processed_list_of_tokens = message_to_token_list(message)\n",
    "\n",
    "  for token in processed_list_of_tokens:\n",
    "    if token not in features:\n",
    "      continue\n",
    "    index = token_to_index_mapping[token]\n",
    "    count_vector[index] += 1\n",
    "  \n",
    "  return count_vector\n",
    "\n",
    "message_to_count_vector('3d b <br> .com bad font font com randoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32., 15., 13.,  7., 12., 30.,  7.,  0., 36., 14.,  7.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_to_count_vector(train_df['MESSAGE'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY                                                     1\n",
       "MESSAGE      \\n\\n<HTML>\\n\\n<HEAD>\\n\\n<TITLE>bizmagoffer</TI...\n",
       "FILE_NAME               00627.4e9619c454da17a27d4a66c87583dd49\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_X_y(dff):\n",
    "  y = dff['CATEGORY'].to_numpy().astype(int)\n",
    "\n",
    "  message_col = dff['MESSAGE']\n",
    "  count_vectors = []\n",
    "\n",
    "  for message in message_col:\n",
    "    count_vector = message_to_count_vector(message)\n",
    "    count_vectors.append(count_vector)\n",
    "\n",
    "  X = np.array(count_vectors).astype(int)\n",
    "\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4636, 11), (4636,), (1160, 11), (1160,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = df_to_X_y(train_df)\n",
    "\n",
    "X_test, y_test = df_to_X_y(test_df)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.00386847, ..., 0.        , 0.2254902 ,\n",
       "        0.02439024],\n",
       "       [0.        , 0.00947867, 0.00386847, ..., 0.        , 0.31372549,\n",
       "        0.1097561 ],\n",
       "       [0.20472441, 0.01421801, 0.00580271, ..., 0.13468013, 0.2745098 ,\n",
       "        0.04065041],\n",
       "       ...,\n",
       "       [0.14173228, 0.12322275, 0.04448743, ..., 0.09427609, 0.        ,\n",
       "        0.00406504],\n",
       "       [0.        , 0.00473934, 0.00386847, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00386847, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       790\n",
      "           1       0.99      0.35      0.52       370\n",
      "\n",
      "    accuracy                           0.79      1160\n",
      "   macro avg       0.88      0.68      0.69      1160\n",
      "weighted avg       0.84      0.79      0.76      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print(classification_report(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89       790\n",
      "           1       0.88      0.59      0.70       370\n",
      "\n",
      "    accuracy                           0.84      1160\n",
      "   macro avg       0.85      0.77      0.80      1160\n",
      "weighted avg       0.85      0.84      0.83      1160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare logistic regression to random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(classification_report(y_test, rf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
